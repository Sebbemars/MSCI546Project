{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sebbemars/MSCI546Project/blob/main/546_Project_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VehIR5uXTPN0"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = 'drive/MyDrive/output.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Data"
      ],
      "metadata": {
        "id": "-5We29bZgjo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('drive/MyDrive/train.csv') #10886\n",
        "test_df = pd.read_csv('drive/MyDrive/test.csv') #6493"
      ],
      "metadata": {
        "id": "F-1Jh4a_TSVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "    df['hour'] = df['datetime'].dt.hour\n",
        "    df['day'] = df['datetime'].dt.day\n",
        "    df['month'] = df['datetime'].dt.month\n",
        "    df['year'] = df['datetime'].dt.year\n",
        "    df['weekday'] = df['datetime'].dt.weekday\n",
        "    df = df.drop(columns=['datetime'])\n",
        "    return df"
      ],
      "metadata": {
        "id": "uCEj-f8VVZpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = preprocess_data(train_df)\n",
        "test_df = preprocess_data(test_df)"
      ],
      "metadata": {
        "id": "Sm1KsmK9TUTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training data into train and validation sets\n",
        "X = train_df.drop(columns=['count', 'casual', 'registered'])\n",
        "#X = train_df.drop(columns =['count','casual','registered','windspeed','atemp'])\n",
        "y = train_df['count']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "W5mzTKCLXZWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "test_df = scaler.transform(test_df)"
      ],
      "metadata": {
        "id": "kZe5a1NyWKv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline"
      ],
      "metadata": {
        "id": "VYKrq4IVjogh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_reg_model = LinearRegression()\n",
        "linear_reg_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Aq0-FGHgjpRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = linear_reg_model.predict(X_test)"
      ],
      "metadata": {
        "id": "fOchvkdikKYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = np.sqrt(mean_squared_log_error(y_test, y_pred.clip(min=0)))"
      ],
      "metadata": {
        "id": "TmK8dg79kgV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation RMSLE: {test_score:.4f}\")"
      ],
      "metadata": {
        "id": "Kx93CyzTknab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge model"
      ],
      "metadata": {
        "id": "Qw8YtQVnZQ7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Ridge model\n",
        "ridge = Ridge(alpha=0.1, random_state=42) #Previous code used crossvalidation and chose alpha = 0.1 as optimal, due to problems with the code the gridsearchCV was removed\n",
        "ridge.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "2mkjKTdpY9d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions and evaluate the model\n",
        "y_pred = ridge.predict(X_test)"
      ],
      "metadata": {
        "id": "YyPBMHdsZTJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = np.sqrt(mean_squared_log_error(y_test, y_pred.clip(min=0)))"
      ],
      "metadata": {
        "id": "QwkB9cTpZV4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation RMSLE: {test_score:.4f}\")"
      ],
      "metadata": {
        "id": "KolKl0dwZZGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso model"
      ],
      "metadata": {
        "id": "FY9XPc7OYzLM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IZ3Qtt-dl7sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Lasso model\n",
        "lasso = Lasso(alpha=0.05, random_state=42) #Previous code used crossvalidation and chose alpha = 0.05 as optimal, due to problems with the code the gridsearchCV was removed\n",
        "lasso.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Ls5MDv9yYTUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions and evaluate the model\n",
        "y_pred = lasso.predict(X_test)"
      ],
      "metadata": {
        "id": "qrMcpEy5YhUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = np.sqrt(mean_squared_log_error(y_test, y_pred.clip(min=0)))"
      ],
      "metadata": {
        "id": "hLT7ecGwYkLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation RMSLE: {test_score:.4f}\")"
      ],
      "metadata": {
        "id": "lMSbf4CJYns9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Model"
      ],
      "metadata": {
        "id": "MlW4AU25Y16X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Decision Tree model\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "dt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "TyDUiTBEXmG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions and evaluate the model\n",
        "y_pred = dt.predict(X_test)"
      ],
      "metadata": {
        "id": "TojDXNmVXvdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = np.sqrt(mean_squared_log_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "D00WoDbUXzUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation RMSLE: {test_score:.4f}\")"
      ],
      "metadata": {
        "id": "BA8VKfGCX3jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "8ZcSmIPSZhtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "HYfp42bmZiiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions and evaluate the model\n",
        "y_pred_train = rf.predict(X_train)\n",
        "y_pred = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "T7seeN0MZnOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = np.sqrt(mean_squared_log_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "uqnFlJnqZriB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation RMSLE: {test_score:.4f}\")"
      ],
      "metadata": {
        "id": "pFkLG-ZqZt7b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}